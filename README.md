# [Multi role-playing large language model demo app](https://openxlab.org.cn/apps/detail/tungwong.chi/mRP-LLM-demo)

## Abstract

Role-playing in conversational AI allows for the simulation of various characters and scenarios, providing rich and diverse interactions. We propose mRP-LLM, a novel approach that integrates multiple role-playing characters into a single model to maximize resource efficiency and expand the model's conversational capabilities.

### References

- Ma Zhiming. (2024). Roleplay-with-XiYou [Data]. Available at https://github.com/JimmyMa99/Roleplay-with-XiYou
- Shanghai AI Laboratory. (2024). InternLM2-Chat-7B [LLM]. Available at https://modelscope.cn/Shanghai_AI_Laboratory/internlm2-chat-7b
- XTuner Contributors. (2023). XTuner: A Toolkit for Efficiently Fine-tuning LLM [Software]. Available at https://github.com/InternLM/xtuner
- InternLM. (2024). Tutorial. Available at https://github.com/InternLM/Tutorial
- InternLM. (2024). InternLM. Available at https://github.com/InternLM/InternLM

## Appendix

### How to Cite This Article

To reference this article, please use the following formats:

```bibtex
@online{mRP-LLM,
    title={Multi role-playing large language model},
    author={Tungwong Chi},
    year={2024},
    month={03},
    url={\url{https://tungwongchi.github.io/blog_md.html?path=archives/mRP-LLM.md}},
}
```

---

&copy; 2020 Tungwong Chi. All rights reserved.
